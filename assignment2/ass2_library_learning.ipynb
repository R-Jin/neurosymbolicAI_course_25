{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky7YpvDseB3C"
      },
      "source": [
        "# Assignment 2 - Symbolic Library Learning\n",
        "\n",
        "Note: this notebook is adapted from the work of Kavi Gupta, Atharva Sehgal, Maddy Bowers and Armando Solar-Lezama, all rights go to them.\n",
        "\n",
        "\n",
        "In this assignment we will try to come up with a DSL (Domain Specific Library) of functions.\n",
        "We will play around with a library called neurosym-lib, which provides a lot of tools to do neuro-symbolic program synthesis.\n",
        "\n",
        "In our case, we will keep things simple: we will find programs specified by our DSL that best fit some data via program enumeration. We will then try to understand how abstractions learning can help with this process.\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Part 1: Defining a DSL (4 points)\n",
        "- Part 2: Finding Programs (3 points)\n",
        "- Part 3: Abstraction Learning (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bOdOCDkTeB3E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting neurosym\n",
            "  Using cached neurosym-0.0.80.tar.gz (150 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting frozendict==2.3.8 (from neurosym)\n",
            "  Using cached frozendict-2.3.8-py311-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from neurosym) (2.3.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from neurosym) (0.18.0)\n",
            "Collecting torchaudio (from neurosym)\n",
            "  Downloading torchaudio-2.9.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from neurosym) (1.26.4)\n",
            "Collecting pytorch-lightning (from neurosym)\n",
            "  Using cached pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting permacache (from neurosym)\n",
            "  Using cached permacache-4.3.1.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: requests in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from neurosym) (2.31.0)\n",
            "Collecting stitch-core==0.1.27 (from neurosym)\n",
            "  Downloading stitch_core-0.1.27-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from neurosym) (1.4.2)\n",
            "Collecting s-exp-parser==1.4.0 (from neurosym)\n",
            "  Using cached s-exp-parser-1.4.0.tar.gz (5.7 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting no_toplevel_code==1.0.0 (from neurosym)\n",
            "  Using cached no-toplevel-code-1.0.0.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting ast-scope==0.5.2 (from neurosym)\n",
            "  Using cached ast_scope-0.5.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pathos==0.3.2 (from neurosym)\n",
            "  Using cached pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting attrs>=19.3.0 (from ast-scope==0.5.2->neurosym)\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting typing-extensions>=4.13.2 (from ast-scope==0.5.2->neurosym)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting ppft>=1.7.6.8 (from pathos==0.3.2->neurosym)\n",
            "  Using cached ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.3.8 (from pathos==0.3.2->neurosym)\n",
            "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.4 (from pathos==0.3.2->neurosym)\n",
            "  Using cached pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.16 (from pathos==0.3.2->neurosym)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: filelock>=3.0.12 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from permacache->neurosym) (3.13.1)\n",
            "Collecting appdirs>=1.4.4 (from permacache->neurosym)\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting tqdm>=4.57.0 (from pytorch-lightning->neurosym)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: PyYAML>5.4 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from pytorch-lightning->neurosym) (6.0.1)\n",
            "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch-lightning->neurosym)\n",
            "  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from pytorch-lightning->neurosym) (23.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->neurosym)\n",
            "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: sympy in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from torch->neurosym) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from torch->neurosym) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from torch->neurosym) (3.1.3)\n",
            "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch->neurosym)\n",
            "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from requests->neurosym) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from requests->neurosym) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from requests->neurosym) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from requests->neurosym) (2025.11.12)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from scikit-learn->neurosym) (1.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from scikit-learn->neurosym) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from scikit-learn->neurosym) (3.4.0)\n",
            "Collecting torch (from neurosym)\n",
            "  Downloading torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->neurosym)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from torch->neurosym) (69.2.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from neurosym)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from torchvision->neurosym) (10.3.0)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from sympy>=1.13.3->torch->neurosym) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning->neurosym) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jonat\\anaconda3\\envs\\sklearn-env\\lib\\site-packages (from jinja2->torch->neurosym) (2.1.3)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->neurosym)\n",
            "  Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
            "     ---------------------------------------- 0.0/77.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 77.6/77.6 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch->neurosym)\n",
            "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
            "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch->neurosym)\n",
            "  Downloading tbb-2021.13.1-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
            "Using cached frozendict-2.3.8-py311-none-any.whl (14 kB)\n",
            "Using cached pathos-0.3.2-py3-none-any.whl (82 kB)\n",
            "Downloading stitch_core-0.1.27-cp312-cp312-win_amd64.whl (685 kB)\n",
            "   ---------------------------------------- 0.0/685.5 kB ? eta -:--:--\n",
            "   ----------------------------- --------- 522.2/685.5 kB 10.9 MB/s eta 0:00:01\n",
            "   --------------------------------------- 685.5/685.5 kB 10.9 MB/s eta 0:00:00\n",
            "Using cached pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
            "Downloading torchaudio-2.9.1-cp312-cp312-win_amd64.whl (665 kB)\n",
            "   ---------------------------------------- 0.0/665.3 kB ? eta -:--:--\n",
            "   --------------------------------------  655.4/665.3 kB 20.8 MB/s eta 0:00:01\n",
            "   --------------------------------------- 665.3/665.3 kB 10.6 MB/s eta 0:00:00\n",
            "Downloading torch-2.9.1-cp312-cp312-win_amd64.whl (110.9 MB)\n",
            "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.6/110.9 MB 19.5 MB/s eta 0:00:06\n",
            "   ---------------------------------------- 1.4/110.9 MB 17.2 MB/s eta 0:00:07\n",
            "    --------------------------------------- 2.1/110.9 MB 19.4 MB/s eta 0:00:06\n",
            "   - -------------------------------------- 2.9/110.9 MB 17.0 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 3.7/110.9 MB 16.8 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 4.4/110.9 MB 16.6 MB/s eta 0:00:07\n",
            "   - -------------------------------------- 5.2/110.9 MB 16.5 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 5.6/110.9 MB 15.5 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 5.9/110.9 MB 15.2 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 6.6/110.9 MB 14.6 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 7.4/110.9 MB 15.2 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 7.8/110.9 MB 14.2 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 8.3/110.9 MB 14.3 MB/s eta 0:00:08\n",
            "   --- ------------------------------------ 8.8/110.9 MB 13.8 MB/s eta 0:00:08\n",
            "   --- ------------------------------------ 9.4/110.9 MB 14.0 MB/s eta 0:00:08\n",
            "   --- ------------------------------------ 10.3/110.9 MB 13.9 MB/s eta 0:00:08\n",
            "   --- ------------------------------------ 10.8/110.9 MB 13.6 MB/s eta 0:00:08\n",
            "   ---- ----------------------------------- 11.6/110.9 MB 13.6 MB/s eta 0:00:08\n",
            "   ---- ----------------------------------- 12.4/110.9 MB 13.6 MB/s eta 0:00:08\n",
            "   ---- ----------------------------------- 13.2/110.9 MB 13.6 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 14.0/110.9 MB 13.6 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 14.7/110.9 MB 13.9 MB/s eta 0:00:07\n",
            "   ----- ---------------------------------- 15.5/110.9 MB 13.6 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 16.2/110.9 MB 14.9 MB/s eta 0:00:07\n",
            "   ------ --------------------------------- 17.0/110.9 MB 14.9 MB/s eta 0:00:07\n",
            "   ------ --------------------------------- 17.7/110.9 MB 15.6 MB/s eta 0:00:06\n",
            "   ------ --------------------------------- 18.5/110.9 MB 15.6 MB/s eta 0:00:06\n",
            "   ------ --------------------------------- 19.3/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   ------- -------------------------------- 19.9/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   ------- -------------------------------- 20.8/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   ------- -------------------------------- 21.5/110.9 MB 16.8 MB/s eta 0:00:06\n",
            "   -------- ------------------------------- 22.2/110.9 MB 16.8 MB/s eta 0:00:06\n",
            "   -------- ------------------------------- 23.0/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   -------- ------------------------------- 23.7/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   -------- ------------------------------- 24.5/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 25.1/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 25.8/110.9 MB 16.0 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 26.6/110.9 MB 16.0 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 27.4/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 28.2/110.9 MB 16.0 MB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 29.0/110.9 MB 16.4 MB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 29.9/110.9 MB 16.4 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 30.7/110.9 MB 16.8 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 31.5/110.9 MB 16.4 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 32.4/110.9 MB 16.8 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 33.2/110.9 MB 16.8 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 34.0/110.9 MB 17.2 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 34.9/110.9 MB 17.7 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 35.8/110.9 MB 17.7 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 36.6/110.9 MB 17.7 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 37.5/110.9 MB 18.2 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 38.1/110.9 MB 18.2 MB/s eta 0:00:05\n",
            "   -------------- ------------------------- 39.1/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 40.0/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 40.8/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 41.6/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 42.5/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 43.4/110.9 MB 18.7 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 44.2/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 44.9/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 45.9/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 46.6/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 47.5/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 48.3/110.9 MB 18.7 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 49.1/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 49.8/110.9 MB 17.7 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 50.8/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 51.7/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 52.6/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 53.3/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 54.2/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 54.9/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 55.9/110.9 MB 18.2 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 56.7/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 57.5/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 58.4/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 59.2/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 59.8/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 60.9/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 61.8/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 62.5/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 63.4/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 64.1/110.9 MB 18.2 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 64.6/110.9 MB 17.7 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 65.4/110.9 MB 17.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 66.6/110.9 MB 17.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 67.2/110.9 MB 17.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 67.2/110.9 MB 17.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 67.9/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 68.8/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 69.5/110.9 MB 16.4 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 70.1/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 71.2/110.9 MB 15.6 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 71.8/110.9 MB 15.6 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 72.8/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 73.7/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 74.5/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 75.4/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 76.3/110.9 MB 16.0 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 77.0/110.9 MB 16.4 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 77.9/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 78.8/110.9 MB 17.7 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 79.6/110.9 MB 17.7 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 80.5/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 81.4/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 82.1/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 83.0/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 83.9/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 84.7/110.9 MB 18.7 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 85.5/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 86.4/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 87.2/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 88.0/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 88.9/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 89.7/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 90.6/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 91.3/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 92.2/110.9 MB 18.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 92.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 94.0/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 94.8/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 95.4/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 96.2/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 97.2/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 98.2/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 98.8/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 99.3/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 100.6/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 101.1/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 102.2/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 103.1/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 103.9/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 104.7/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 105.6/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 106.4/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 107.3/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  108.2/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  108.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  109.6/110.9 MB 19.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.6/110.9 MB 17.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 110.9/110.9 MB 2.2 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.24.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
            "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.7/4.3 MB 22.1 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 1.4/4.3 MB 21.6 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 2.4/4.3 MB 19.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 3.3/4.3 MB 19.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 4.1/4.3 MB 18.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  4.3/4.3 MB 18.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  4.3/4.3 MB 18.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.3/4.3 MB 12.5 MB/s eta 0:00:00\n",
            "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "   ---------------------------------------- 0.0/150.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 150.3/150.3 kB 4.5 MB/s eta 0:00:00\n",
            "Using cached pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Using cached ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl (453 kB)\n",
            "   ---------------------------------------- 0.0/453.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 453.5/453.5 kB 9.4 MB/s eta 0:00:00\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
            "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 44.6/44.6 kB 2.1 MB/s eta 0:00:00\n",
            "Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl (46 kB)\n",
            "   ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 46.1/46.1 kB 2.2 MB/s eta 0:00:00\n",
            "Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
            "   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 41.7/41.7 kB 2.0 MB/s eta 0:00:00\n",
            "Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
            "   ---------------------------------------- 0.0/87.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 87.2/87.2 kB ? eta 0:00:00\n",
            "Building wheels for collected packages: neurosym, ast-scope, no_toplevel_code, s-exp-parser, permacache\n",
            "  Building wheel for neurosym (setup.py): started\n",
            "  Building wheel for neurosym (setup.py): finished with status 'done'\n",
            "  Created wheel for neurosym: filename=neurosym-0.0.80-py3-none-any.whl size=212501 sha256=6c7c7a5315b01d57393f00149c4d8d33e79b484b5f2388351b5f301e4d7be334\n",
            "  Stored in directory: c:\\users\\jonat\\appdata\\local\\pip\\cache\\wheels\\f4\\5d\\8c\\32917d04517141b7b621c59fa8a87760496d10fe0cd5cbf7cd\n",
            "  Building wheel for ast-scope (setup.py): started\n",
            "  Building wheel for ast-scope (setup.py): finished with status 'done'\n",
            "  Created wheel for ast-scope: filename=ast_scope-0.5.2-py3-none-any.whl size=10512 sha256=6722fdc7b6d84c0ea2c059383696d5675142b4ae677eaca474d6eb2f312f2f71\n",
            "  Stored in directory: c:\\users\\jonat\\appdata\\local\\pip\\cache\\wheels\\50\\94\\e0\\d2b2a7eeccc001e28b78fd5e9379e1f7ab6138280850ab7706\n",
            "  Building wheel for no_toplevel_code (setup.py): started\n",
            "  Building wheel for no_toplevel_code (setup.py): finished with status 'done'\n",
            "  Created wheel for no_toplevel_code: filename=no_toplevel_code-1.0.0-py3-none-any.whl size=3569 sha256=38a45dd2de6a53210254c54ab6e629f63ab512bb8249226300face2789eb8442\n",
            "  Stored in directory: c:\\users\\jonat\\appdata\\local\\pip\\cache\\wheels\\d9\\ec\\df\\13d82d5f2f7a387595a8bf02e6c8ddf7ab9484754eb1e49c73\n",
            "  Building wheel for s-exp-parser (setup.py): started\n",
            "  Building wheel for s-exp-parser (setup.py): finished with status 'done'\n",
            "  Created wheel for s-exp-parser: filename=s_exp_parser-1.4.0-py3-none-any.whl size=7568 sha256=6f911ac40defac44a128dd7b16dac89f511b98fab505352bbd43a333ea0ce68e\n",
            "  Stored in directory: c:\\users\\jonat\\appdata\\local\\pip\\cache\\wheels\\7f\\5e\\61\\bab21d6f62c85bae79b4a95dcbb492d9faa752824928a0d38f\n",
            "  Building wheel for permacache (setup.py): started\n",
            "  Building wheel for permacache (setup.py): finished with status 'done'\n",
            "  Created wheel for permacache: filename=permacache-4.3.1-py3-none-any.whl size=36748 sha256=6a04ea27738f84fbec8621154327d50df1dc7813726e1f356ee76e8ddca9becb\n",
            "  Stored in directory: c:\\users\\jonat\\appdata\\local\\pip\\cache\\wheels\\86\\2c\\f6\\aa3094efcb0bc395747b432dd84eaee3feae5587577ea9f88f\n",
            "Successfully built neurosym ast-scope no_toplevel_code s-exp-parser permacache\n",
            "Installing collected packages: appdirs, typing-extensions, tqdm, sympy, stitch-core, propcache, ppft, pox, permacache, no_toplevel_code, multidict, fsspec, frozenlist, frozendict, dill, attrs, aiohappyeyeballs, yarl, torch, s-exp-parser, multiprocess, lightning-utilities, ast-scope, aiosignal, torchvision, torchmetrics, torchaudio, pathos, aiohttp, pytorch-lightning, neurosym\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.12\n",
            "    Uninstalling sympy-1.12:\n",
            "      Successfully uninstalled sympy-1.12\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0\n",
            "    Uninstalling torch-2.3.0:\n",
            "      Successfully uninstalled torch-2.3.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0\n",
            "    Uninstalling torchvision-0.18.0:\n",
            "      Successfully uninstalled torchvision-0.18.0\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 appdirs-1.4.4 ast-scope-0.5.2 attrs-25.4.0 dill-0.4.0 frozendict-2.3.8 frozenlist-1.8.0 fsspec-2025.10.0 lightning-utilities-0.15.2 multidict-6.7.0 multiprocess-0.70.18 neurosym-0.0.80 no_toplevel_code-1.0.0 pathos-0.3.2 permacache-4.3.1 pox-0.3.6 ppft-1.7.7 propcache-0.4.1 pytorch-lightning-2.5.6 s-exp-parser-1.4.0 stitch-core-0.1.27 sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchmetrics-1.8.2 torchvision-0.24.1 tqdm-4.67.1 typing-extensions-4.15.0 yarl-1.22.0\n"
          ]
        }
      ],
      "source": [
        "! pip install neurosym \n",
        "# %pip install neurosym - might have to use this line instead if run locally\n",
        "# Note: make sure your python version is >= 3.10 or the import will not work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRhS-_1YzO0B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.2\n"
          ]
        }
      ],
      "source": [
        "# check python version is >=3.10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S7Z-p4fYeB3F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jonat\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import neurosym as ns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IddDNFCreB3F"
      },
      "source": [
        "## Part 1: Defining a DSL (4 points)\n",
        "\n",
        "We would like to be able to define arithmetic functions, of various types.\n",
        "\n",
        "### Exercise 1A: Create a DSL\n",
        "\n",
        "We would like our DSL to be able to represent the following functions. **For future experiments, make sure you don't include cosine.**\n",
        "\n",
        "- $f_0(x) = x + 1$\n",
        "- $f_1(x) = x^2 + \\frac{x}{\\sin x}$\n",
        "- $f_2(x) = (x + 2)^x$\n",
        "- $f_3(x) = \\begin{cases}\n",
        "x^2 & x < 0\\\\\n",
        "\\sqrt {x^2 + 1} & x \\geq 0\\\\\n",
        "\\end{cases}$\n",
        "\n",
        "To add a new symbol to the DSL grammar, you should use the function `dslf.production()`.\n",
        "Here is a description of that function:\n",
        "\n",
        "    production(self, symbol: str, type_str: str, semantics: object)\n",
        "        Add a parameterized production to the DSL.\n",
        "\n",
        "        :param symbol: The symbol for the production.\n",
        "        :param type_str: The type string for the production.\n",
        "        :param semantics: The semantics to use for the production. This should have\n",
        "            a type corresponding to ``type_str``. Note: *this is not checked*.\n",
        "\n",
        "Meaning that the first parameter is the symbol you will use for the DSL primitive, the second is the type of the function, and the third is the actual python function implementation (using numpy functions here can be useful).\n",
        "\n",
        "We have defined an incomplete DSL grammar below. Your task is to extend it so all of the examples above can be expressed.\n",
        "\n",
        "**Hint 1**: try adding at least one new constant symbol, one or more binary operators, and one ternary operator (if-else) that appear in the above example to the DSL grammar.\n",
        "\n",
        "**Hint 2**: for the if-else operator, we suggest making a general if-else of type $(c, f, f) \\rightarrow f$. The first argument should be a conditional expression of type c (a boolean), such as \"x > 0\" in the example above. The two remaining arguments (of type f) should be the two alternatives of the if-else returned depending on whether the first argument is true or false.\n",
        "\n",
        "Then, a specific if-else expression like the one shown in the above example can be constructed by choosing the first parameter of the if-else to be a specific conditional expression (e.g. using the \"<\" function provided, of type (f, f) -> c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XSFYEBGOeB3F"
      },
      "outputs": [],
      "source": [
        "dslf = ns.DSLFactory()\n",
        "dslf.production(\"0\", \"() -> f\", lambda: 0) # constant 0, no arguments\n",
        "dslf.production(\"1\", \"() -> f\", lambda: 1)\n",
        "dslf.production(\"2\", \"() -> f\", lambda: 2)\n",
        "dslf.production(\"sqrt\", \"(f) -> f\", np.sqrt) # square root, one argument\n",
        "dslf.production(\"*\", \"(f, f) -> f\", lambda x, y: x * y) # multiplication, two arguments\n",
        "dslf.production(\"<\", \"(f, f) -> c\", lambda x,y: x < y) # less than, two arguments, returns a boolean\n",
        "\n",
        "\"YOUR CODE HERE\"\n",
        "dslf.production(\"+\", \"(f, f) -> f\", lambda x, y: x + y)\n",
        "dslf.production(\"**\", \"(f, f) -> f\", lambda x, y: x**y)\n",
        "dslf.production(\"/\", \"(f, f) -> f\", lambda x, y: x / y)\n",
        "dslf.production(\"sin\", \"(f) -> f\", np.sin)\n",
        "dslf.production(\"ife\", \"(c, f, f) -> f\", lambda c, x, y : x if c else y )\n",
        "\n",
        "dslf.lambdas()\n",
        "dslf.prune_to(\"f -> f\")\n",
        "dsl = dslf.finalize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET-2c6YGeB3F"
      },
      "source": [
        "### DSL Printout\n",
        "\n",
        "See your DSL printed below, and ensure it is what you would expect!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bEpLA3uWeB3G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              0 :: () -> f\n",
            "              1 :: () -> f\n",
            "              2 :: () -> f\n",
            "           sqrt :: f -> f\n",
            "              * :: (f, f) -> f\n",
            "              < :: (f, f) -> c\n",
            "              + :: (f, f) -> f\n",
            "             ** :: (f, f) -> f\n",
            "              / :: (f, f) -> f\n",
            "            sin :: f -> f\n",
            "            ife :: (c, f, f) -> f\n",
            "            lam :: L<#body|f> -> f -> #body\n",
            "           $0_0 :: V<f@0>\n"
          ]
        }
      ],
      "source": [
        "print(dsl.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrofhWUheB3G"
      },
      "source": [
        "### Exercise 1B: Write your functions\n",
        "\n",
        "We have provided $f_0$, it is up to you to write $f_1$ through $f_3$.\n",
        "\n",
        "How you represent your functions is by putting their symbol first, then their arguments afterwards. E.g. for the function x + 1, we get the function sum and add the parameters after, resulting in: \\+ x 1. Here both x and 1 are functions with no inputs, so we can report them like this\n",
        "\n",
        "Note that $0_0 represents the input variable x. Be sure to use in the other functions as well. Also remember the parenthesis like we have in the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Js86gSLbeB3G"
      },
      "outputs": [],
      "source": [
        "f_0 = \"(lam (+ ($0_0) (1)))\"\n",
        "\"YOUR CODE HERE\"\n",
        "f_1 = \"(lam (+ (** ($0_0) (2)) (/ ($0_0) (sin ($0_0)))))\"\n",
        "f_2 = \"(lam (** (+ ($0_0) (2)) ($0_0)))\"\n",
        "f_3 = \"(lam (ife (< ($0_0) (0)) (** ($0_0) (2)) (sqrt (+ (** ($0_0) (2)) (1)))))\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMcX0nqhzAAH"
      },
      "source": [
        "Run the tests in the following cell to make sure your DSL and programs are working properly. If you have not defined the functions correctly, you will get an AssertionError."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1avySn4DeB3G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "def test_program(actual_program, expected_fn):\n",
        "    actual_fn = dsl.compute(dsl.initialize(ns.parse_s_expression(actual_program)))\n",
        "    inputs = np.linspace(-1, 1, 100)\n",
        "    actual = np.array([actual_fn(x) for x in inputs])\n",
        "    expected = np.array([expected_fn(x) for x in inputs])\n",
        "    delta = np.abs(actual - expected)\n",
        "    bad = delta > 1e-5\n",
        "    if (~bad).all():\n",
        "        return\n",
        "    [[bad_input, *_]] = np.where(bad)\n",
        "    raise AssertionError(f\"On input {inputs[bad_input]}, expected {expected[bad_input]} but recvd {actual[bad_input]}\")\n",
        "\n",
        "test_program(f_0, lambda x: x + 1)\n",
        "test_program(f_1, lambda x: x ** 2 + x / np.sin(x))\n",
        "test_program(f_2, lambda x: (x + 2) ** x)\n",
        "test_program(f_3, lambda x: x ** 2 if x < 0 else (x ** 2 + 1) ** 0.5)\n",
        "print(\"All tests passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOmFzDejeB3G"
      },
      "source": [
        "## Part 2: Finding Programs (3 points)\n",
        "\n",
        "To begin with, we will build programs with our DSL by enumerating them. We will sample uniformly terms from our library, forming programs from this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MD_S3qM-eB3G"
      },
      "outputs": [],
      "source": [
        "dist_family = ns.BigramProgramDistributionFamily(dsl)\n",
        "uniform = dist_family.uniform()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lU7tEWNeB3G"
      },
      "source": [
        "We can enumerate programs from this distribution by running the `dist_family.enumerate` command.\n",
        "This produces an infinite stream of programs, which we can limit with `islice` as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "C7rXmlNdeB3G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(lam ($0_0)) -2.397895336151123\n",
            "(lam (0)) -2.397895336151123\n",
            "(lam (1)) -2.397895336151123\n",
            "(lam (2)) -2.397895336151123\n",
            "(lam (sin ($0_0))) -4.795790672302246\n",
            "(lam (sin (0))) -4.795790672302246\n",
            "(lam (sin (1))) -4.795790672302246\n",
            "(lam (sin (2))) -4.795790672302246\n",
            "(lam (sqrt ($0_0))) -4.795790672302246\n",
            "(lam (sqrt (0))) -4.795790672302246\n",
            "(lam (sqrt (1))) -4.795790672302246\n",
            "(lam (sqrt (2))) -4.795790672302246\n",
            "(lam (* ($0_0) ($0_0))) -7.193686008453369\n",
            "(lam (* ($0_0) (0))) -7.193686008453369\n",
            "(lam (* ($0_0) (1))) -7.193686008453369\n",
            "(lam (* ($0_0) (2))) -7.193686008453369\n",
            "(lam (* (0) ($0_0))) -7.193686008453369\n",
            "(lam (* (0) (0))) -7.193686008453369\n",
            "(lam (* (0) (1))) -7.193686008453369\n",
            "(lam (* (0) (2))) -7.193686008453369\n",
            "(lam (* (1) ($0_0))) -7.193686008453369\n",
            "(lam (* (1) (0))) -7.193686008453369\n",
            "(lam (* (1) (1))) -7.193686008453369\n",
            "(lam (* (1) (2))) -7.193686008453369\n",
            "(lam (* (2) ($0_0))) -7.193686008453369\n",
            "(lam (* (2) (0))) -7.193686008453369\n",
            "(lam (* (2) (1))) -7.193686008453369\n",
            "(lam (* (2) (2))) -7.193686008453369\n",
            "(lam (** ($0_0) ($0_0))) -7.193686008453369\n",
            "(lam (** ($0_0) (0))) -7.193686008453369\n",
            "(lam (** ($0_0) (1))) -7.193686008453369\n",
            "(lam (** ($0_0) (2))) -7.193686008453369\n",
            "(lam (** (0) ($0_0))) -7.193686008453369\n",
            "(lam (** (0) (0))) -7.193686008453369\n",
            "(lam (** (0) (1))) -7.193686008453369\n",
            "(lam (** (0) (2))) -7.193686008453369\n",
            "(lam (** (1) ($0_0))) -7.193686008453369\n",
            "(lam (** (1) (0))) -7.193686008453369\n",
            "(lam (** (1) (1))) -7.193686008453369\n",
            "(lam (** (1) (2))) -7.193686008453369\n",
            "(lam (** (2) ($0_0))) -7.193686008453369\n",
            "(lam (** (2) (0))) -7.193686008453369\n",
            "(lam (** (2) (1))) -7.193686008453369\n",
            "(lam (** (2) (2))) -7.193686008453369\n",
            "(lam (+ ($0_0) ($0_0))) -7.193686008453369\n",
            "(lam (+ ($0_0) (0))) -7.193686008453369\n",
            "(lam (+ ($0_0) (1))) -7.193686008453369\n",
            "(lam (+ ($0_0) (2))) -7.193686008453369\n",
            "(lam (+ (0) ($0_0))) -7.193686008453369\n",
            "(lam (+ (0) (0))) -7.193686008453369\n"
          ]
        }
      ],
      "source": [
        "for prog, like in itertools.islice(dist_family.enumerate(uniform), 50):\n",
        "    print(ns.render_s_expression(prog), like)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BNAPVoQzAAI"
      },
      "source": [
        "What are the programs with the highest likelihood? Can you briefly explain why?\n",
        "\n",
        "**Your answer:** Any two arguments programs, notably the programs with \"*\", \"**\" since those have more possible permutations posible to generate within the span."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlOIFmDQeB3H"
      },
      "source": [
        "### Exercise 2: Finding a program\n",
        "\n",
        "Finish the following function below, which, given a distribution, a list of inputs and a list of outputs, finds a program matching those inputs and outputs, within epsilon at all locations. It might be helpful to look at the `test_program` method above to see how to run programs.\n",
        "\n",
        "Important detail: you will want to handle errors and `nan` values gracefully. For this, we provide the `run_safely` function, that takes a function and input and runs it, returning `None` if its output is `nan` or an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GUeWrKleB3H"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # suppress warnings about run-time errors we catch.\n",
        "\n",
        "\n",
        "def run_safely(f, x):\n",
        "    try:\n",
        "        y = f(x)\n",
        "    except:\n",
        "        return None\n",
        "    if np.isnan(y):\n",
        "        return None\n",
        "    return y\n",
        "\n",
        "def find_program(dist, inputs, outputs, epsilon):\n",
        "    for prog, _ in dist_family.enumerate(dist):\n",
        "        fn = dsl.compute(dsl.initialize(prog))\n",
        "        # Now you can use fn to safely evaluate the program at each input in inputs,\n",
        "        # and compare the output you get from fn(input) to the correpsonding y in outputs\n",
        "        ...\n",
        "        # If the program returns None (from run_safely) or is not within epsilon for all expected outputs, it is not your program, continue searching. Otherwise, it's our program!\n",
        "        ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSWbr66beB3H"
      },
      "source": [
        "Let's look at what types of programs our search is finding for some functions we provide!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN_4P4O8eB3H"
      },
      "outputs": [],
      "source": [
        "def find_program_for_function(dist, fn, epsilon):\n",
        "    inputs = np.linspace(-2, 2)\n",
        "    outputs = fn(inputs)\n",
        "    return find_program(dist, inputs, outputs, epsilon)\n",
        "\n",
        "print(ns.render_s_expression(find_program_for_function(uniform, lambda x: x * 2, 0)))\n",
        "print(ns.render_s_expression(find_program_for_function(uniform, np.abs, 0.001)))\n",
        "print(ns.render_s_expression(find_program_for_function(uniform, lambda x: x + 0.05, 0.1)))\n",
        "print(ns.render_s_expression(find_program_for_function(uniform, lambda x: x ** 2, 0.1)))\n",
        "print(ns.render_s_expression(find_program_for_function(uniform, lambda x: (x ** 2 + 1) ** 0.5, 0.1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN1pkVLazAAJ"
      },
      "source": [
        "Run the tests to assure that the programs you are finding are the expected ones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puA3cr6OzAAJ"
      },
      "outputs": [],
      "source": [
        "assert ns.render_s_expression(find_program_for_function(uniform, lambda x: x * 2, 0)) == '(lam (* ($0_0) (2)))'\n",
        "assert ns.render_s_expression(find_program_for_function(uniform, np.abs, 0.001)) == '(lam (sqrt (* ($0_0) ($0_0))))'\n",
        "assert ns.render_s_expression(find_program_for_function(uniform, lambda x: x + 0.05, 0.1)) == '(lam ($0_0))'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v2WumtleB3H"
      },
      "source": [
        "You will notice in the second test above, the enumerator came up with a \"creative\" solution to the absolute value problem. This is because this ended up being an easier to find solution than the more obvious if-then-else program we might have come up, given our DSL:\n",
        "\n",
        " -x if x < 0 else x\n",
        "\n",
        "which in the DSL syntax, given some functions ite (if-then-else), < and - are defined, looks like:\n",
        "\n",
        " `(lam (ite (< ($0_0) (0)) (- (0) ($0_0)) ($0_0)))`\n",
        "\n",
        "\n",
        "\n",
        "The following cell will take slightly longer to run, but you can see that it is able to identify a solution for $\\cos^2 \\theta$\n",
        "\n",
        "Note: depending on your CPU, the search for $\\cos^2 \\theta$ might time out. If it does, don't worry about it. It is not needed for the remainder of the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9yLMj8reB3H"
      },
      "outputs": [],
      "source": [
        "ns.render_s_expression(find_program_for_function(uniform, lambda x: np.cos(x) ** 2, 0.001))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3fQD0Z1zAAJ"
      },
      "source": [
        "What primitive do we need to add to our library to be able to find a program for $\\cos \\theta$? (Remember, you are not allowed to add directly $\\cos$! Think back to trigonometric formulas...) Go back to where you have defined your DSL and add it, then come back to the next cell.\n",
        "\n",
        "Note: the time it takes to find a program for $\\cos \\theta$ will depend on the exact DSL grammar as well as the CPU used. In our tests we observed the following search times:\n",
        "- on an Apple M4 CPU: between 7 seconds and 7 min;\n",
        "- on Colab: at least 28 seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJlstj4_zAAJ"
      },
      "outputs": [],
      "source": [
        "ns.render_s_expression(find_program_for_function(uniform, lambda x: np.cos(x), 0.001))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kehMI-LzAAJ"
      },
      "source": [
        "What did you add?\n",
        "\n",
        "Your answer: ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFAdIBr8eB3H"
      },
      "source": [
        "## Part 3: Abstraction Learning (3 points)\n",
        "\n",
        "Here we will try to understand how we can do better than just sampling programs uniformly at random when we have some data we want to find programs for, and how abstractions can help within this process.\n",
        "\n",
        "We start by introducing a dataset of smoothed sequences. These sequences have values roughly in the range $[-2, 2]$. We generate this data below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09obgP-meB3H"
      },
      "outputs": [],
      "source": [
        "num_sequences = 1000\n",
        "len_sequences = 100\n",
        "xs = np.linspace(-10, 10, len_sequences, dtype=np.float32)\n",
        "slack = 20\n",
        "stride = 4\n",
        "values = np.random.RandomState(1).rand(num_sequences, len_sequences + slack) * 4 - 2\n",
        "values = np.mean([values[:, i:i + len_sequences] for i in range(slack)], axis=0)\n",
        "values *= np.sqrt(slack)\n",
        "values = values[:, ::stride]\n",
        "values = values.astype(np.float32)\n",
        "xs = xs[::stride]\n",
        "\n",
        "plot_count = 3\n",
        "\n",
        "def plot_some_sequences():\n",
        "    for i in range(plot_count):\n",
        "        plt.plot(xs, values[i], color=f\"C{i}\", alpha=0.25)\n",
        "        plt.scatter(xs, values[i], color=f\"C{i}\", marker=\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHgqelgaeB3H"
      },
      "outputs": [],
      "source": [
        "plot_some_sequences()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsgvLKWbeB3I"
      },
      "source": [
        "We provide a function for finding the best program out of a list that matches a given data sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77I-dm8peB3I"
      },
      "outputs": [],
      "source": [
        "def evaluate_all_programs(dsl, programs):\n",
        "    filtered_programs, evaluations = [], []\n",
        "    for prog in programs:\n",
        "        try:\n",
        "            actual_fn = dsl.compute(dsl.initialize(prog))\n",
        "        except:\n",
        "            continue\n",
        "        ys = []\n",
        "        for inp in xs:\n",
        "            y = run_safely(actual_fn, inp)\n",
        "            if y is None or not (-2 <= y <= 2):\n",
        "                break\n",
        "            ys.append(y)\n",
        "        else:\n",
        "            filtered_programs.append(prog)\n",
        "            evaluations.append(ys)\n",
        "    return filtered_programs, np.array(evaluations)\n",
        "\n",
        "def best_fits(dsl, family, dist):\n",
        "    programs = [prog for prog, _ in itertools.islice(family.enumerate(dist), 5000)]\n",
        "    programs = sorted(programs, key=lambda x: len(ns.render_s_expression(x)))\n",
        "    filtered_programs, ys = evaluate_all_programs(dsl, programs)\n",
        "    errors = ((ys[None] - values[:,None]) ** 2).sum(-1)\n",
        "    program_idxs = errors.argmin(1)\n",
        "    print(\"Mean error: \", errors.min(1).mean())\n",
        "    return [filtered_programs[i] for i in program_idxs]\n",
        "\n",
        "def plot_programs_against_data(dsl, best_programs):\n",
        "    plot_some_sequences()\n",
        "    best_programs = best_programs[:plot_count]\n",
        "    _, evals = evaluate_all_programs(dsl, best_programs)\n",
        "    for prog, ev in zip(best_programs, evals):\n",
        "        plt.plot(xs, ev, label=ns.render_s_expression(prog).replace(\"$\", r\"\\$\"))\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-yZCMHheB3I"
      },
      "source": [
        "Now we find the best programs among the first 50k enumerated programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t1LwsmyeB3I"
      },
      "outputs": [],
      "source": [
        "best_programs = best_fits(dsl, dist_family, uniform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgHUOqCxeB3I"
      },
      "outputs": [],
      "source": [
        "plot_programs_against_data(dsl, best_programs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS_LozRreB3I"
      },
      "source": [
        "### Exercise 3A: Fitting a DSL\n",
        "\n",
        "Now we will refine our search. First, we fit a distribution to the `best_programs`. We will bound the minimum likelihood of each symbol at 0.01, but feel free to try and change it. If you do so, comment on the result:\n",
        "\n",
        "...\n",
        "\n",
        "Check with the functions defined above how the mean error changes now that we have fitted the distribution to the best programs, and plot the new programs like above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEjNjFVYeB3J"
      },
      "outputs": [],
      "source": [
        "fitted_dist = dist_family.fit_distribution(best_programs).bound_minimum_likelihood(0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUyDkyejeB3J"
      },
      "outputs": [],
      "source": [
        "# Check that the fitted distribution actually makes the error smaller\n",
        "\n",
        "best_programs_fitted = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB7z6pAYeB3J"
      },
      "outputs": [],
      "source": [
        "# Plot the best programs\n",
        "plot_count = 4\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-41FKzBjeB3K"
      },
      "source": [
        "### Exercise 3B: Abstractions\n",
        "\n",
        "Let's now introduce abstractions to our DSL. This means going through the best programs we have already found, find common subsequences, and abstract them into new symbols of our DSL.\n",
        "\n",
        "We will introduce 5 new abstractions. Once done, obtain a new distribution family from the new DSL as we have done before, and then fit a distribution from that family to the rewritten programs. Bound also that distribution to a minimum likelihood of 0.01:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFW7aS9aeB3K"
      },
      "outputs": [],
      "source": [
        "abstraction_dsl, rewritten = ns.compression.multi_step_compression(dsl, best_programs_fitted, 5)\n",
        "abstraction_family = ...\n",
        "abstraction_dist = ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr15IbaseB3K"
      },
      "source": [
        "Visualize your dsl and the new abstractions that have been introduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVNyh39deB3K"
      },
      "outputs": [],
      "source": [
        "# visualize dsl\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRlt-ulLzAAP"
      },
      "source": [
        "Can you understand which functions do the abstractions introduced refer to? (Note: #number in the definition of the abstraction refer to a input parameter.)\n",
        "\n",
        "Your answer:\n",
        "\n",
        "1. ...\n",
        "\n",
        "2. ...\n",
        "\n",
        "3. ...\n",
        "\n",
        "4. ...\n",
        "\n",
        "5. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QVVRPrGeB3K"
      },
      "source": [
        "Now check that the abstractions have had a positive effect to the mean error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU3Evb9teB3K"
      },
      "outputs": [],
      "source": [
        "best_programs_abstractions = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53_6WbQWzAAQ"
      },
      "source": [
        "Finally, let's plot some programs against the data and see how they fit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFWS1gEgeB3L"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5YNBcrMzAAQ"
      },
      "source": [
        "Hopefully, by now you understand how abstractions are important and how they make it easier to find better and better programs the more we intertwine search and introduction of abstractions.\n",
        "\n",
        "We search for programs, introduce abstractions, find better programs with the abstractions, then introduce more asbtractions... and so on! Dreamcoder, which you have seen in the lectures, is a great example of this mechanism, and the results they obtain in their paper (https://arxiv.org/abs/2006.08381) is a testament of how powerful methods that combine library learning with neural networks can be."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sklearn-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
